# This experiment run a single TikV instance and periodically increases the number of clients.
# This goal is to find the maximum number of clients after which the instance utilization does not increase further.
apiVersion: frisbee.io/v1alpha1
kind: Workflow
metadata:
  name: saturate-tikv
spec:
  withTelemetry:
    importMonitors: [ "sysmon/container", "ycsbmon/client" ]
    ingress:
      host: platform.science-hangar.eu

  withTestOracle:
    pass: >-
      {{.IsSuccessful "runners"}} == true

  actions:
    # Step 0: bootstrap.
    # For TiKV, we must first create a placementDriver and then add the workers.
    - action: Service
      name: master
      service:
        fromTemplate:
          templateRef: tikv/placementDriver
          inputs:
            { cpu: "4", memory: "8Gi" }


    - action: Cluster
      depends: { running: [ master ] }
      name: workers
      cluster:
        templateRef: tikv/worker
        instances: 1
        inputs:
          - { placementDriver: .service.master.any,  cpu: "8", memory: "32Gi" }


    # Step 1: Load a new dataset, using the parameters of workload A.
    # We use no throttling to maximize this step and complete it soon.
    - action: Cluster
      name: loaders
      depends: { running: [ master, workers ] }
      cluster:
        templateRef: ycsb-tikv/loader
        inputs:
          - { server: .service.master.any, recordcount: "1000000", offset: "0", threads: "400" }


    # Step 2: Periodically increase the load. Use Grafana to find the utilization, throughput, and tail latency.
    - action: Cluster
      name: runners
      depends: { running: [ master, workers ], success: [ loaders ] }
      cluster:
        templateRef: ycsb-tikv/runner
        instances: 40
        inputs:
          - { server: .service.master.any, workload: workloada, operationcount: "100000000", threads: "4" }
        schedule:
          cron: "@every 2m"