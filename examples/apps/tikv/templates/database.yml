---
# In some situations such as in the Docker or NAT network environment, if the other nodes (peers) cannot access
# the PD node through the default peer URLs listened to by this PD node, you must manually set the advertise peer URLs.
apiVersion: frisbee.dev/v1alpha1
kind: Template
metadata:
  name: tikv.cluster.placement-driver
spec:
  service:
    decorators: # Decorators
      telemetry: [ system.telemetry.resources, tikv.telemetry.pd ]

    volumes: # Create an ephemeral volume, backed by a file
      - name: scratch-volume
        ephemeral:
          volumeClaimTemplate:
            spec:
              storageClassName: platform.storageclass.local
              accessModes:
                - ReadWriteOnce
              resources:
                requests:
                  storage: 15Gi

    containers: # Container
      - name: main
        image: pingcap/pd:v5.1.2
        volumeMounts:
          - name: scratch-volume
            mountPath: /store
        ports:
          - name: to-clients
            containerPort: 2379
          - name: to-cluster
            containerPort: 2380
        command:
          - /bin/sh   # Run shell
          - -c        # Read from string
          - |         # Multi-line str
            set -eum
            cut -d ' ' -f 4 /proc/self/stat > /dev/shm/app # Sidecar: use it for entering the cgroup

            rm -rf /store/$${HOSTNAME}
            mkdir -p /store/$${HOSTNAME}/pd

            # see https://github.com/tikv/pd/blob/master/conf/config.toml

            echo "Start PD server at $${HOSTNAME}"

            /pd-server                                                  \
            --client-urls=http://0.0.0.0:2379                           \
            --advertise-client-urls=http://$${HOSTNAME}:2379            \
            --peer-urls=http://0.0.0.0:2380                             \
            --advertise-peer-urls=http://$${HOSTNAME}:2380              \
            --data-dir=/store/$${HOSTNAME}/pd


---
apiVersion: frisbee.dev/v1alpha1
kind: Template
metadata:
  name: tikv.cluster.worker
spec:
  inputs:
    parameters:
      placementDriver: "localhost"
  service:
    decorators: # Decorators
      telemetry: [ system.telemetry.resources, tikv.telemetry.worker ]

    volumes: # Create an ephemeral volume, backed by a file
      - name: scratch-volume
        ephemeral:
          volumeClaimTemplate:
            spec:
              storageClassName: platform.storageclass.local
              accessModes:
                - ReadWriteOnce
              resources:
                requests:
                  storage: 15Gi

    containers: # Container
      - name: main
        image: pingcap/tikv:v5.1.2
        volumeMounts:
          - name: scratch-volume
            mountPath: /store
        ports:
          - name: clusterbus
            containerPort: 20160
        securityContext:
          capabilities:
            add: [ "SYS_RESOURCE" ]
        command:
          - /bin/sh   # Run shell
          - -c        # Read from string
          - |         # Multi-line str
            set -eum
            cut -d ' ' -f 4 /proc/self/stat > /dev/shm/app # Sidecar: use it for entering the cgroup

            # increase the maximum number of open file descriptors
            ulimit -n 82920

            rm -rf /store/$${HOSTNAME}
            mkdir -p /store/$${HOSTNAME}/data

            # see https://github.com/tikv/tikv/blob/master/etc/config-template.toml
            cat > config.toml <<EOF
            [server]
              addr="0.0.0.0:20160"
              advertise-addr="$${HOSTNAME}:20160"

              # used by the prometheus agent
              status-addr = "127.0.0.1:20180"

            [pd]
              endpoints = ["{{"{{.inputs.parameters.placementDriver}}"}}:2379"]

            [storage]
              reserve-space = "0"
              data-dir = "/store/$${HOSTNAME}/data"
            EOF

            /tikv-server --config=config.toml
