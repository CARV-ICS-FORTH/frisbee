---
apiVersion: frisbee.io/v1alpha1
kind: Workflow
metadata:
  name: state-driven
spec:
  withTelemetry:
    importDashboards:
      - platform.telemetry.container
      - ycsb.telemetry.client
      - tikv.telemetry.pd
      - tikv.telemetry.worker

  actions:
    # Init: init victim
    - action: Service
      name: victim
      service:
        templateRef: platform.tools.debugger


    # Step 0: bootstrap.
    # For TiKV, we must first create a placementDriver and then add the workers.
    - action: Service
      name: master
      service:
        templateRef: tikv.cluster.placement-driver

    - action: Cluster
      depends: { running: [ master ] }
      name: workers
      cluster:
        templateRef: tikv.cluster.worker
        instances: 1
        inputs:
          - { placementDriver: .service.master.one }

    # Step 1: Load a new dataset, using the parameters of workload A.
    # We use no throttling to maximize this step and complete it soon.
    - action: Service
      depends: { running: [ workers ] }
      name: loader
      service:
        templateRef: ycsb.tikv.loader
        inputs:
          - { server: .service.master.one, workload: workloada, recordcount: "500000", threads: "2" }

    # Step 2: Run workload A
    - action: Service
      depends: { success: [ loader ] }
      name: workload-a
      service:
        templateRef: ycsb.tikv.runner
        inputs:
          - { server: .service.master.one, workload: workloada, operationcount: "500000", threads: "2" }

    # Step 3: Run workload B
    - action: Service
      depends: { success: [ workload-a ] }
      name: workload-b
      service:
        templateRef: ycsb.tikv.runner
        inputs:
          - { server: .service.master.one, workload: workloadb, operationcount: "500000", threads: "2" }

    # Step 4: Run workload C
    - action: Service
      depends: { success: [ workload-b ] }
      name: workload-c
      service:
        templateRef: ycsb.tikv.runner
        inputs:
          - { server: .service.master.one, workload: workloadc, operationcount: "500000", threads: "2" }

    # Step 5: Run workload F
    - action: Service
      depends: { success: [ workload-c ] }
      name: workload-f
      service:
        templateRef: ycsb.tikv.runner
        inputs:
          - { server: .service.master.one, workload: workloadf, operationcount: "500000", threads: "2" }


    # Step 6: Run workload D.
    - action: Service
      depends: { success: [ workload-f ] }
      name: workload-d
      service:
        templateRef: ycsb.tikv.runner
        inputs:
          - { server: .service.master.one, workload: workloadd, operationcount: "500000", threads: "2" }


    # Step 7,8: Reload the data with parameters of workload E.
    # We use the dropdata field to remove all data before test.
    - action: Service
      depends: { success: [ workload-d ] }
      name: reloader
      service:
        templateRef: ycsb.tikv.loader
        inputs:
          - { server: .service.master.one, workload: workloade, dropdata: "true", recordcount: "500000", threads: "2" }

    # Step 9:Run workload E
    - action: Service
      depends: { success: [ reloader ] }
      name: workload-e
      service:
        templateRef: ycsb.tikv.runner
        inputs:
          - { server: .service.master.one, workload: workloade, operationcount: "500000", threads: "2" }


    # This part control when the failure will be injected
    - action: Chaos
      name: partition0
      depends: { running: [ victim ], success: [ loader ] }
      chaos:
        templateRef: paper.partition.fault
        inputs:
          - { target: .service.victim.one, duration: "3m" }